{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Term Document matrix and Cosine similarity",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8PQZuPFwk8ep6+zhWbMIx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skssushil/Web-mining/blob/master/2_Term_Document_matrix_and_Cosine_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7HL8kIO2NMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5d4fc4ce-867e-4917-ff22-6e4902803527"
      },
      "source": [
        "import urllib.request\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import math\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKDTmyDOxyDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "03069bf2-1122-4f66-d54b-42ea3dd1f31a"
      },
      "source": [
        "from google.colab import files\n",
        "try:\n",
        "    from googlesearch import search\n",
        "except ImportError:\n",
        "    print(\"No module named 'google' found\")\n",
        "# to search\n",
        "query =[\"tutorial on datastructure\", \"data science\", \"web mining\",\" Artificial intelegence\"]\n",
        "url=[]\n",
        "for i in query:\n",
        "  q=[]\n",
        "  for j in search(i, tld=\"com\", num=5, stop=10, pause=2):\n",
        "    q.append(j)\n",
        "  url.append(q)\n",
        "print(url)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['https://www.tutorialspoint.com/data_structures_algorithms/index.htm', 'https://www.tutorialspoint.com/data_structures_algorithms/data_structures_basics.htm', 'https://www.tutorialspoint.com/data_structures_algorithms/algorithms_basics.htm', 'https://www.tutorialspoint.com/data_structures_algorithms/dsa_useful_resources.htm', 'https://www.tutorialspoint.com/data_structures_algorithms/stack_algorithm.htm', 'https://www.youtube.com/watch?v=RBSGKlAvoiM', 'https://www.geeksforgeeks.org/data-structures/', 'https://www.javatpoint.com/data-structure-tutorial', 'https://www.javatpoint.com/data-structure-interview-questions', 'https://www.javatpoint.com/data-structure-introduction'], ['https://www.kainos.com/my-experience-as-a-data-scientist', 'https://en.wikipedia.org/wiki/Data_science', 'https://en.wikipedia.org/wiki/Master_in_Data_Science', 'https://en.wikipedia.org/wiki/Big_data', 'https://en.wikipedia.org/wiki/Data_analysis', 'https://en.wikipedia.org/wiki/Unstructured_data', 'https://datascience.berkeley.edu/about/what-is-data-science/', 'https://www.innoarchitech.com/blog/what-is-data-science-does-data-scientist-do', 'https://dataconomy.com/2020/07/9-best-practices-every-data-science-leader-should-follow/', 'https://www.ilounge.com/articles/5-data-science-trends-to-watch-out-for-in-2020'], ['https://www.researchgate.net/figure/Web-Mining-Categories-5_fig1_276928728', 'https://en.wikipedia.org/wiki/Web_mining', 'https://en.wikipedia.org/wiki/Web_mining#Web_mining_types', 'https://en.wikipedia.org/wiki/Web_mining#Web_usage_mining', 'https://en.wikipedia.org/wiki/Web_mining#Web_structure_mining', 'https://en.wikipedia.org/wiki/Web_mining#Web_content_mining', 'https://www.geeksforgeeks.org/web-mining/', 'https://www.techopedia.com/definition/15634/web-mining', 'https://www.sciencedirect.com/topics/computer-science/web-mining', 'https://searchcustomerexperience.techtarget.com/definition/Web-mining'], ['https://en.wikipedia.org/wiki/Artificial_intelligence', 'https://en.wikipedia.org/wiki/History_of_artificial_intelligence', 'https://en.wikipedia.org/wiki/Outline_of_artificial_intelligence', 'https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach', 'https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/powerful-ai-can-now-be-trained-on-a-single-computer', 'https://www.fool.com/investing/2020/07/17/nvidia-tough-new-rival-artificial-intelligence-ai.aspx', 'https://www.wired.com/story/best-ai-models-no-match-coronavirus/', 'https://builtin.com/artificial-intelligence', 'https://futureoflife.org/background/benefits-risks-of-artificial-intelligence/', 'https://www.investopedia.com/terms/a/artificial-intelligence-ai.asp']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKtqhkF79lxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_text=\" \""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2pPSYYXLxIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Length=len(url)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_4NZpgGMVIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Length1=len(url[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7CVpvP3x7k3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=[]\n",
        "for i in range(Length):\n",
        "  for j in range(Length1):\n",
        "    req = urllib.request.Request(url[i][j], headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    data = urllib.request.urlopen(req).read()\n",
        "    html= data.decode()\n",
        "    soup = BeautifulSoup(html,features=\"lxml\")\n",
        "    for script in soup([\"script\", \"style\"]):\n",
        "      script.extract()\n",
        "    # get text\n",
        "    text = soup.get_text()\n",
        "    # break into lines and remove leading and trailing space on each\n",
        "    lines = (line.strip() for line in text.splitlines())\n",
        "    # break multi-headlines into a line each\n",
        "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "    # drop blank lines\n",
        "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "  f_text=f_text+text\n",
        "  dataset.append(f_text)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FxI6zhPPdpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M=len(dataset)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrytoZxcnuRt",
        "colab_type": "text"
      },
      "source": [
        "Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_H0RJjynI5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_lower_case(data):\n",
        "  return np.char.lower(data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCIPhwW-Aa3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_string_special_characters(data):\n",
        "    # removes special characters with ' '\n",
        "    stripped = re.sub('[^a-zA-z\\s]', '', data)\n",
        "    stripped = re.sub('_', '', stripped)\n",
        "\n",
        "    # Change any white space to one space\n",
        "    stripped = re.sub('\\s+', ' ', stripped)\n",
        "\n",
        "    # Remove start and end white spaces\n",
        "    stripped = stripped.strip()\n",
        "    return stripped.lower()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSaA9wl_AitZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming(data):\n",
        "    stemmer= PorterStemmer()    \n",
        "    tokens = word_tokenize(str(data))\n",
        "    new_text = \"\"\n",
        "    for w in tokens:\n",
        "        new_text = new_text + \" \" + stemmer.stem(w)\n",
        "    return new_text"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YVdzhfqApv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_numbers(data):\n",
        "    tokens = word_tokenize(str(data))\n",
        "    new_text = \"\"\n",
        "    for w in tokens:\n",
        "        try:\n",
        "            w = num2words(int(w))\n",
        "        except:\n",
        "            a = 0\n",
        "        new_text = new_text + \" \" + w\n",
        "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
        "    return new_text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU-LGOgUAsTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stopword removal\n",
        "def remove_stop_words(data):\n",
        "    stop_words = stopwords.words('english')\n",
        "    words = word_tokenize(str(data))\n",
        "    new_text = \"\"\n",
        "    for w in words:\n",
        "        if w not in stop_words and len(w) > 1:\n",
        "            new_text = new_text + \" \" + w\n",
        "    return new_text"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTkJEAlSoIGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(data):\n",
        "  Clean_data= remove_string_special_characters(data)  # removing special character\n",
        "  Clean_data=stemming(Clean_data)\n",
        "  Clean_data= convert_numbers(Clean_data)\n",
        "  Clean_data=remove_stop_words(Clean_data)\n",
        "  return Clean_data\n",
        "# preprocessing of data completed"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX3LPZk4ogV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_text1 = []\n",
        "for i in dataset[:M]:\n",
        "    processed_text1.append(str(preprocess(i)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIheX2VDQ5Uw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8762c1a8-db54-411e-861c-bc07772590eb"
      },
      "source": [
        "print(len(processed_text1))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72k996WwPKYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'Doc1': [processed_text1[0]],'Doc2': [processed_text1[1]],'Doc3': [processed_text1[2]],'Doc4': [processed_text1[3]]})"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_hgh2YBP7JC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "75f6eac3-982e-4bb6-f547-40ba64bfd760"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Doc1  ...                                               Doc4\n",
            "0   ds introduct javatpoint home data structur ja...  ...   ds introduct javatpoint home data structur ja...\n",
            "\n",
            "[1 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB40aRv0P-I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize\n",
        "vectorizer = TfidfVectorizer()\n",
        "doc_vec = vectorizer.fit_transform(df.iloc[0])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4elQKdfRp-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dataFrame\n",
        "df2 = pd.DataFrame(doc_vec.toarray().transpose(),\n",
        "                   index=vectorizer.get_feature_names())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roX076cdRu4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change column headers\n",
        "df2.columns = df.columns"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InawEcFLS98R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3=pd.DataFrame(vectorizer.get_feature_names())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdCcGjpcRz8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "75703db2-e348-4a4b-f9c0-45df0c9a3e1a"
      },
      "source": [
        "print(df2.head(50))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      Doc1      Doc2      Doc3      Doc4\n",
            "aapl              0.000000  0.000000  0.000000  0.007846\n",
            "abil              0.000000  0.000000  0.000000  0.007846\n",
            "abl               0.000000  0.000000  0.000000  0.007846\n",
            "abov              0.008472  0.005754  0.004693  0.008189\n",
            "abstract          0.033890  0.023017  0.018773  0.016378\n",
            "academi           0.000000  0.000000  0.000000  0.007846\n",
            "accept            0.000000  0.000000  0.007091  0.006186\n",
            "access            0.000000  0.014076  0.017222  0.015024\n",
            "accessori         0.000000  0.049267  0.040185  0.035057\n",
            "account           0.000000  0.000000  0.007091  0.030930\n",
            "accru             0.000000  0.000000  0.007091  0.006186\n",
            "accur             0.000000  0.014076  0.011481  0.010016\n",
            "achiev            0.000000  0.014076  0.011481  0.015024\n",
            "acquia            0.000000  0.000000  0.014182  0.012372\n",
            "across            0.000000  0.007038  0.005741  0.010016\n",
            "act               0.000000  0.000000  0.000000  0.007846\n",
            "action            0.000000  0.000000  0.000000  0.031385\n",
            "activ             0.000000  0.000000  0.000000  0.007846\n",
            "actual            0.000000  0.000000  0.007091  0.006186\n",
            "ad                0.008472  0.011508  0.014080  0.012283\n",
            "adapt             0.000000  0.007038  0.005741  0.005008\n",
            "add               0.000000  0.000000  0.014182  0.012372\n",
            "addit             0.000000  0.000000  0.007091  0.006186\n",
            "address           0.008472  0.005754  0.046934  0.040945\n",
            "adjac             0.016945  0.011508  0.009387  0.008189\n",
            "adopt             0.000000  0.035191  0.034444  0.030049\n",
            "adt               0.016945  0.011508  0.009387  0.008189\n",
            "advanc            0.008472  0.005754  0.004693  0.008189\n",
            "advantag          0.008472  0.005754  0.004693  0.004094\n",
            "advertis          0.000000  0.014076  0.017222  0.025041\n",
            "advic             0.000000  0.000000  0.000000  0.007846\n",
            "advisor           0.000000  0.000000  0.000000  0.015692\n",
            "advisori          0.000000  0.000000  0.000000  0.007846\n",
            "adword            0.008472  0.005754  0.004693  0.004094\n",
            "affect            0.000000  0.000000  0.007091  0.012372\n",
            "affili            0.008472  0.011508  0.009387  0.008189\n",
            "age               0.059307  0.040279  0.032854  0.028661\n",
            "agre              0.000000  0.000000  0.028363  0.024744\n",
            "ai                0.008472  0.005754  0.014080  0.090078\n",
            "aid               0.000000  0.000000  0.007091  0.006186\n",
            "aim               0.000000  0.007038  0.011481  0.015024\n",
            "air               0.000000  0.014076  0.011481  0.010016\n",
            "airplay           0.000000  0.014076  0.011481  0.010016\n",
            "airpod            0.000000  0.014076  0.011481  0.010016\n",
            "ajax              0.008472  0.005754  0.004693  0.004094\n",
            "alexa             0.000000  0.000000  0.000000  0.007846\n",
            "algorithm         0.059307  0.040279  0.032854  0.040945\n",
            "algorithmicautom  0.000000  0.000000  0.000000  0.007846\n",
            "alik              0.000000  0.000000  0.000000  0.007846\n",
            "allinon           0.000000  0.000000  0.007091  0.006186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ-SRfVqmwru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_list=[*url[0],*url[1],*url[2],*url[3]]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCWnTL3sm_L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc=[]\n",
        "for k in url_list:\n",
        "  req = urllib.request.Request(k, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "  data = urllib.request.urlopen(req).read()\n",
        "  html= data.decode()\n",
        "  soup = BeautifulSoup(html,features=\"lxml\")\n",
        "  for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "  # get text\n",
        "  text = soup.get_text()\n",
        "  # break into lines and remove leading and trailing space on each\n",
        "  lines = (line.strip() for line in text.splitlines())\n",
        "  # break multi-headlines into a line each\n",
        "  chunks = (phrase.strip() for line in lines for phrase in line.split(\" \"))\n",
        "  # drop blank lines\n",
        "  text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "  doc.append(text)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7MtTl3XnB-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N=len(doc)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOoqRks3ngfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_text = []\n",
        "for i in doc[:N]:\n",
        "    processed_text.append(word_tokenize(str(preprocess(i))))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mblB50kEnjsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8fccb6b-7383-489a-ce49-fa5c7b4604f9"
      },
      "source": [
        "len(processed_text)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB0wwMxXoDZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DF = {}\n",
        "for i in range(N):\n",
        "    tokens = processed_text[i]\n",
        "    for w in tokens:\n",
        "        try:\n",
        "            DF[w].add(i)\n",
        "        except:\n",
        "            DF[w] = {i}\n",
        "for i in DF:\n",
        "    DF[i] = len(DF[i])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA4HdN2zoF9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5570e4d9-3a8f-49ec-babb-10a5710e9a6f"
      },
      "source": [
        "total_vocab_size = len(DF)\n",
        "print(total_vocab_size)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWbE2uspoIMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_vocab = [x for x in DF]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdPHq50ZoLcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "502a9843-2505-46b0-c2ea-2996709bffa1"
      },
      "source": [
        "print(total_vocab[:20])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data', 'structur', 'algorithm', 'tutori', 'tutorialspoint', 'home', 'job', 'tool', 'code', 'ground', 'current', 'affair', 'upsc', 'note', 'onlin', 'tutor', 'whiteboard', 'net', 'meet', 'tutorix']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDonY4zOoNYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doc_freq(word):\n",
        "    c = 0\n",
        "    try:\n",
        "        c = DF[word]\n",
        "    except:\n",
        "        pass\n",
        "    return c"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WAPGRnBoSPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = 0\n",
        "tf_idf = {}\n",
        "for i in range(N):    \n",
        "    tokens = processed_text[i]    \n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)    \n",
        "    for token in np.unique(tokens):        \n",
        "        tf = counter[token]/words_count\n",
        "        df = doc_freq(token)\n",
        "        idf = np.log((N+1)/(df+1))        \n",
        "        tf_idf[doc, token] = tf*idf\n",
        "    doc += 1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUzLz_ASoU7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e04678b-4a66-49bc-eca2-bedf542a3034"
      },
      "source": [
        "len(tf_idf)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDE5_lAUoYM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_sim(a, b):\n",
        "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "    return cos_sim"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gTPGSz9oaQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = np.zeros((N, total_vocab_size))\n",
        "for i in tf_idf:\n",
        "    try:\n",
        "        ind = total_vocab.index(i[1])\n",
        "        D[i[0]][ind] = tf_idf[i]\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQRPhjFyocxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_vector(tokens):\n",
        "    Q = np.zeros((len(total_vocab)))\n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)\n",
        "    query_weights = {}\n",
        "    for token in np.unique(tokens):   \n",
        "        tf = counter[token]/words_count\n",
        "        df = doc_freq(token)\n",
        "        idf = math.log((N+1)/(df+1))\n",
        "        try:\n",
        "            ind = total_vocab.index(token)\n",
        "            Q[ind] = tf*idf\n",
        "        except:\n",
        "            pass\n",
        "    return Q"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7on4uy8ofYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(query):\n",
        "    preprocessed_query = preprocess(query)\n",
        "    tokens = word_tokenize(str(preprocessed_query))\n",
        "    print(\"\")\n",
        "    #print(tokens)\n",
        "    d_cosines = []\n",
        "    query_vector = gen_vector(tokens)\n",
        "    for d in D:\n",
        "        d_cosines.append(cosine_sim(query_vector, d))\n",
        "    return d_cosines"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4olrD_NoiG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ce8e9d0a-38f9-450b-8149-4fbe82878c6a"
      },
      "source": [
        "Arr1=np.array(cosine_similarity(query[0]))\n",
        "Arr2=np.array(cosine_similarity(query[1]))\n",
        "Arr3=np.array(cosine_similarity(query[2]))\n",
        "Arr4=np.array(cosine_similarity(query[3]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqlg0Hgcok8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Arr1=np.sort(Arr1)[::-1]\n",
        "Arr2=np.sort(Arr2)[::-1]\n",
        "Arr3=np.sort(Arr3)[::-1]\n",
        "Arr4=np.sort(Arr4)[::-1]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bKV6siaonq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2f2da1bd-fa36-40df-84a1-8ef239009967"
      },
      "source": [
        "print(Arr1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.05897758 0.05779178 0.03642241 0.03534395 0.03203201 0.02679438\n",
            " 0.02553508 0.02075446 0.01743775 0.01237658 0.01093245 0.00792001\n",
            " 0.00563358 0.00034619 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej1Rdlhlopl5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4bc9da98-e671-42a5-ecbd-9c7e79630c5f"
      },
      "source": [
        "print(Arr2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.17978494 0.09535605 0.06523546 0.0618833  0.04922685 0.04874491\n",
            " 0.04784486 0.04350746 0.03336656 0.02994366 0.0272546  0.02410809\n",
            " 0.02109992 0.02091013 0.02091013 0.02091013 0.02091013 0.02091013\n",
            " 0.01604274 0.01590294 0.01387858 0.01367625 0.01195706 0.01091454\n",
            " 0.00998544 0.00967544 0.00953125 0.00914965 0.00909868 0.00825618\n",
            " 0.00791113 0.00674686 0.00591415 0.00527856 0.00525766 0.0049694\n",
            " 0.00417058 0.00289409 0.00167538 0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA53GhoWos-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e0932051-36cc-4867-bc3b-5e2b889fb73c"
      },
      "source": [
        "print(Arr3)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.59446764 0.59446764 0.59446764 0.59446764 0.59446764 0.3953234\n",
            " 0.35475221 0.20773843 0.1928689  0.15600632 0.03983378 0.03046217\n",
            " 0.0145968  0.01433358 0.01146937 0.01058769 0.01002637 0.00996139\n",
            " 0.00894279 0.00710005 0.00508511 0.00506153 0.0043481  0.00378828\n",
            " 0.0036416  0.00290146 0.00234979 0.0018741  0.00181861 0.00178224\n",
            " 0.00164819 0.0013139  0.00106179 0.001042   0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya9lm9NwowRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3782cd9e-6ec8-42c7-cf69-8530aaf35685"
      },
      "source": [
        "print(Arr4)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.29138245 0.28159108 0.22318172 0.14886502 0.14670798 0.12527171\n",
            " 0.05937472 0.03772473 0.02592894 0.02437975 0.02116451 0.02116451\n",
            " 0.02116451 0.02116451 0.02116451 0.0192547  0.01022796 0.00767739\n",
            " 0.00678025 0.00673492 0.00531669 0.00485003 0.00232908 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmO6x7CqoyM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}