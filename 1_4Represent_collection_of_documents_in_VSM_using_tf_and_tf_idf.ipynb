{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_4Represent collection of documents in VSM using tf and tf*idf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAASipTLXmGV50h2Z7H3EW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skssushil/Web-mining/blob/master/1_4Represent_collection_of_documents_in_VSM_using_tf_and_tf_idf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cTyXW7YntUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "49791ba7-8dc8-45b1-c360-9ceeae0d1488"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "import copy\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import math\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsHZmMrn5gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "with open('CISI.ALL') as f:\n",
        "    lines = \"\"\n",
        "    for l in f.readlines():\n",
        "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "    lines = lines.lstrip(\"\\n\").split(\"\\n\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-dlf5Nzn8fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_set = {}\n",
        "doc_id = \"\"\n",
        "doc_text = \"\"\n",
        "for l in lines:\n",
        "    if l.startswith(\".I\"):\n",
        "        doc_id = l.split(\" \")[1].strip()\n",
        "    elif l.startswith(\".X\"):\n",
        "        doc_set[doc_id] = doc_text.lstrip(\" \")\n",
        "        doc_id = \"\"\n",
        "        doc_text = \"\"\n",
        "    else:\n",
        "        doc_text += l.strip()[3:] + \" \" # The first 3 characters of a line can be ignored."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQWJoeKosKsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = []\n",
        "for i in doc_set.values():\n",
        "  dataset.append(i)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhoCrMqxsPq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7064739c-2a6b-4111-b69f-6759c1e1e6e6"
      },
      "source": [
        "N=len(dataset)\n",
        "print(N)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX68WlS48-1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "with open('CISI.QRY') as g:\n",
        "    qlines = \"\"\n",
        "    for m in g.readlines():\n",
        "        qlines += \"\\n\" + m.strip() if m.startswith(\".\") else \" \" + m.strip()\n",
        "    qlines = qlines.lstrip(\"\\n\").split(\"\\n\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vEevXj69C1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qry_set = {}\n",
        "qry_id = \"\"\n",
        "qry_text=\"\"\n",
        "for m in qlines:\n",
        "    if m.startswith(\".I\"):\n",
        "        qry_id = m.split(\" \")[1].strip()\n",
        "    elif m.startswith(\".W\"):\n",
        "        qry_set[qry_id] = m.strip()[3:]\n",
        "        qry_id = \"\"\n",
        "squery=qry_set[\"1\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL7xSCXIslYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_lower_case(data):\n",
        "    return np.char.lower(data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD-gvAEqu8ZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def remove_stop_words(data):\n",
        "    stop_words = stopwords.words('english')\n",
        "    words = word_tokenize(str(data))\n",
        "    new_text = \"\"\n",
        "    for w in words:\n",
        "        if w not in stop_words and len(w) > 1:\n",
        "            new_text = new_text + \" \" + w\n",
        "    return new_text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMAHI1bru-Im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(data):\n",
        "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
        "    for i in range(len(symbols)):\n",
        "        data = np.char.replace(data, symbols[i], ' ')\n",
        "        data = np.char.replace(data, \"  \", \" \")\n",
        "    data = np.char.replace(data, ',', '')\n",
        "    return data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67kO5X1tvAbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_apostrophe(data):\n",
        "    return np.char.replace(data, \"'\", \"\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAWZhjkdvCuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming(data):\n",
        "    stemmer= PorterStemmer()\n",
        "    \n",
        "    tokens = word_tokenize(str(data))\n",
        "    new_text = \"\"\n",
        "    for w in tokens:\n",
        "        new_text = new_text + \" \" + stemmer.stem(w)\n",
        "    return new_text"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ByQPnQ4vFgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import inflect \n",
        "p = inflect.engine() \n",
        "  \n",
        "# convert number into words \n",
        "def convert_number(text): \n",
        "    # split string into list of words \n",
        "    temp_str = text.split() \n",
        "    # initialise empty list \n",
        "    new_string = [] \n",
        "  \n",
        "    for word in temp_str: \n",
        "        # if word is a digit, convert the digit \n",
        "        # to numbers and append into the new_string list \n",
        "        if word.isdigit(): \n",
        "            temp = p.number_to_words(word) \n",
        "            new_string.append(temp) \n",
        "  \n",
        "        # append the word as it is \n",
        "        else: \n",
        "            new_string.append(word) \n",
        "  \n",
        "    # join the words of new_string to form a string \n",
        "    temp_str = ' '.join(new_string) \n",
        "    return temp_str"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKqY9tfWvHnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(data):\n",
        "    data = convert_number(data)\n",
        "    data = convert_lower_case(data)\n",
        "    data = remove_punctuation(data) #remove comma seperately\n",
        "    data = remove_apostrophe(data)\n",
        "    data = remove_stop_words(data)\n",
        "    data = stemming(data)\n",
        "    data = remove_punctuation(data)\n",
        "    data = stemming(data) #needed again as we need to stem the words\n",
        "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
        "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
        "    data = convert_number(data)\n",
        "    return data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPlDNQPTvJsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_text = []\n",
        "for i in dataset[:N]:\n",
        "    processed_text.append(word_tokenize(str(preprocess(i))))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkehvI7BvfWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DF = {}\n",
        "\n",
        "for i in range(N):\n",
        "    tokens = processed_text[i]\n",
        "    for w in tokens:\n",
        "        try:\n",
        "            DF[w].add(i)\n",
        "        except:\n",
        "            DF[w] = {i}\n",
        "for i in DF:\n",
        "    DF[i] = len(DF[i])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLOPZwHUv7J_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0684300b-e43a-451d-c4cb-04a9cb5eca36"
      },
      "source": [
        "total_vocab_size = len(DF)\n",
        "print(total_vocab_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6830\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTrKiU7hwGPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_vocab = [x for x in DF]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q83798vXwP65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "68ad1fc9-8bca-49ad-8ea4-fe9f2457ca92"
      },
      "source": [
        "print(total_vocab[:20])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['eighteen', 'edit', 'dewey', 'decim', 'classif', 'comaromi', 'present', 'studi', 'histori', 'first', 'ddc', 'publish', 'one', 'thousand', ',', 'eight', 'hundred', 'and', 'seventy-six', 'eighteenth']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf99rQcvx9F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doc_freq(word):\n",
        "    c = 0\n",
        "    try:\n",
        "        c = DF[word]\n",
        "    except:\n",
        "        pass\n",
        "    return c"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGQd-vfiwUDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = 0\n",
        "tf_idf = {}\n",
        "for i in range(N):    \n",
        "    tokens = processed_text[i]    \n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)    \n",
        "    for token in np.unique(tokens):        \n",
        "        tf = counter[token]/words_count\n",
        "        df = doc_freq(token)\n",
        "        idf = np.log((N+1)/(df+1))        \n",
        "        tf_idf[doc, token] = tf*idf\n",
        "    doc += 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWFutrsWxqJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = 0\n",
        "tf_idf = {}\n",
        "for i in range(N):    \n",
        "    tokens = processed_text[i]    \n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)    \n",
        "    for token in np.unique(tokens):        \n",
        "        tf = counter[token]/words_count\n",
        "        df = doc_freq(token)\n",
        "        idf = np.log((N+1)/(df+1))        \n",
        "        tf_idf[doc, token] = tf*idf\n",
        "    doc += 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgd81dnnyNk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f940be3-f16e-4e93-8e69-ca1759703e60"
      },
      "source": [
        "tf_idf[(0, 'abroad')]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08722407845274038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5CANIK2ytN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "225e153e-894e-47b4-a394-0d56a5a96323"
      },
      "source": [
        "len(tf_idf)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc1UzyOFzhNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matching_score(k, query):\n",
        "    preprocessed_query = preprocess(query)\n",
        "    tokens = word_tokenize(str(preprocessed_query))\n",
        "    print(\"\\nQuery:\", query)  \n",
        "    query_weights = {}\n",
        "    for key in tf_idf:        \n",
        "        if key[1] in tokens:\n",
        "            try:\n",
        "                query_weights[key[0]] += tf_idf[key]\n",
        "            except:\n",
        "                query_weights[key[0]] = tf_idf[key]    \n",
        "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(\"\")  \n",
        "    print(\"Top Matching Documents\")  \n",
        "    l = []\n",
        "    for i in query_weights[:10]:\n",
        "        l.append(i[0])    \n",
        "    print(l)\n",
        "    for i in range(k):\n",
        "      x=l[i]\n",
        "      print(\"    \", l[i],\" \", dataset[x])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dw6TJ40z8Lv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "584e3876-44e6-4585-8901-e916de3a1864"
      },
      "source": [
        "matching_score(10, squery)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Query: What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n",
            "\n",
            "Top Matching Documents\n",
            "[1293, 448, 446, 314, 1280, 443, 428, 564, 721, 1162]\n",
            "     1293   Automatic Text Analysis Salton, G. In this article the principal experiments in automatic text analysis are briefly reviewed, and an indication is given of developments to be expected in the future. \n",
            "     448   Situational Relevance Wilson, Patrick The concept of situational relevance is introduced, based on W.S.Cooper's definitions of logical relevance, on the notion of evidential relevance drawn from inductive logic, on the notions of a personal stock of knowledge and a set of personal concerns, the latter explained in terms of preferences over ranges of alternatives.. Situationally relevant items of information are those that answer, or logically help to answer, questions of concern.. Significant situationally relevant information is explained in terms of changes of view in relation to questions of concern.. It is claimed that situational relevance is an explication of the ordinary notion of practical relevance, and that it is the appropriate relevance concept to use in evaluation of systems supplying practically relevant information.. \n",
            "     446   A Note on the Concept of \"Relevance\" Foskett, D.J. Two recent articles in this journal (Konigova [1], Cooper [2]) have gone beyond the usual slapdash use of the words \"relevant\" and \"relevance,\" and have attempted to explicate the concept further.  Both attempts only partially succeed.  Konigova proposes three types:  formal relevance, subject/content relevance and subjective relevance (or pertinency).  This classification has validity, but is not further elaborated, and indeed she reverts to a less precise language; for example, in defining \"second order noise,\" she uses the ambiguous phrase \"a formally relevant document which is not really relevant\" - presumably meaning not subjectively relevant, according to the real need of the enquirer.  And in her mathematics, as she admits, \"no account is taken of the subjective relevance (pertinence).\"  Yet this is surely the true aim of the system. \n",
            "     314   Automatic Abstracting and Indexing - Survey and Recommendations Edmundson, H.P. Wyllys, R.E. In preparation for the widespread use of automatic scanner which will read documents and transmit their contents in automatic analysis: the relative- frequency approach to measuring the significance of words, word groups, and sentences.. The relative-frequency approach is discussed in detail, as is its application to problems of automatic indexing and automatic abstracting.. Included in the report is a summary of automatic analysis studies published as of the date of writing.. Conclusions are drawn that point toward more sophisticated mathematical and linguistic techniques for the solution of problems of automatic analysis.. \n",
            "     1280   Relative Effectiveness of Document Titles and Abstracts for Determining Relevance of Documents Resnick, A. Abstract.  Individuals who received documents through a selective dissemination of information system were asked to determine the relevance of documents to their work interests on the basis of titles and of abstracts.  The results indicate that there was no significant difference between the usefulness of titles and of abstracts for this purpose. \n",
            "     443   On Relevance as a Measure Coffman, William Relevance is defined as a measure of information conveyed by a document relative to a query.. It is shown that the relationship between the document and the query, though necessary, is not sufficient to determine relevance.. \n",
            "     428   The Information Content of Titles in Engineering Literature Bottle, Robert T. Since many alerting and information services rely very heavily on the use of titles to transfer information to the potential user, it is essential that he be aware of the proportion of the information contained in the complete document which will not be deducible from the title and which he will therefore miss.. Methods will be discussed for analyzing the relative information content of the titles of engineering paper and results presented for the amount and type of information lost through scanning title listing only.. Between one-third and one-half of indexable terms are not retrievable from article titles even if all possible synonyms and  related terms are used.. If all synonyms are used instead of one keyword the amount of information retrieved is increased by about 70 percent.. The problems of dealing with synonyms and with syntactical variants in searching titles indexes are discussed.. The possibility of using keywords in journal titles as supplementary retrieval tags is suggested since they were deemed useful in nearly one-third of the sample of papers analyzed.. \n",
            "     564   Computer Evaluation of Indexing and Text Processing Salton, G. Lesk, M. E. Automatic indexing methods are evaluated and design criteria for modern information system are derived.. Information retrieval, indexing methods, automatic retrieval, information systems, document retrieval, text analysis, document handling, retrieval effectiveness, SMART, precision, recall.. \n",
            "     721   Information Transfer Limitations of Titles of Chemical Documents Bottle, R.R. Seeley, C.R. Some methods of estimating the minimum amounts of information in a document not retrievable through its title are discussed.  An analysis of the information transferred by different types of keywords is helpful in planning search strategies, e.g., 30% of chemical substances mentioned in journal articles are not discernable in their titles even when broad class names are used as synonyms.  Patents have considerably less informative titles than journal articles.  In nuclear science, report titles are also less informative than those of journal articles, but the proportion of reports with completely uninformative titles is now only 10% of the 1957 value.  Titles in chemistry are more informative than those in most other fields, but the use of alerting and other services based on titles requires a good understanding of the underlying information transfer principles. \n",
            "     1162   The Thesaurus and some Methods of its Construction.  Part 1. Ovchinnikov, V.G. It is suggested that the thesaurus be considered a hierarchical system for classifying factors. The problem of automatic construction of thesaurus is posed. A formal description \"input\" and \"output\" of this problem is given; a series of classificational concepts is formulated. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOvDr01d0Klu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_sim(a, b):\n",
        "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "    return cos_sim"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1KyJtwM0fyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = np.zeros((N, total_vocab_size))\n",
        "for i in tf_idf:\n",
        "    try:\n",
        "        ind = total_vocab.index(i[1])\n",
        "        D[i[0]][ind] = tf_idf[i]\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSIhv9ox0lLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_vector(tokens):\n",
        "    Q = np.zeros((len(total_vocab)))\n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)\n",
        "    query_weights = {}\n",
        "    for token in np.unique(tokens):   \n",
        "        tf = counter[token]/words_count\n",
        "        df = doc_freq(token)\n",
        "        idf = math.log((N+1)/(df+1))\n",
        "        try:\n",
        "            ind = total_vocab.index(token)\n",
        "            Q[ind] = tf*idf\n",
        "        except:\n",
        "            pass\n",
        "    return Q"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnwswVva0n1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(k, query):\n",
        "    print(\"Cosine Similarity\")\n",
        "    preprocessed_query = preprocess(query)\n",
        "    tokens = word_tokenize(str(preprocessed_query))\n",
        "    print(\"\\nQuery:\", query)\n",
        "    print(\"\")\n",
        "    #print(tokens)\n",
        "    d_cosines = []\n",
        "    query_vector = gen_vector(tokens)\n",
        "    for d in D:\n",
        "        d_cosines.append(cosine_sim(query_vector, d))\n",
        "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
        "    print(\"\")  \n",
        "    print(out)\n",
        "    print(\"Cosine similarity\",\" id \", \" Document\")\n",
        "    for i in range(k):\n",
        "      x=out[i]\n",
        "      print(round(d_cosines[x],10),\"    \", out[i],\" \", dataset[x])\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3yLjitS0r9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "c78fc163-12b5-49c5-df4b-e8edef881fbe"
      },
      "source": [
        "cosine_similarity(10,squery)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine Similarity\n",
            "\n",
            "Query: What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n",
            "\n",
            "\n",
            "[ 721  428  588  602 1280  812 1298  710  835   37]\n",
            "Cosine similarity  id   Document\n",
            "0.3699478965      721   Information Transfer Limitations of Titles of Chemical Documents Bottle, R.R. Seeley, C.R. Some methods of estimating the minimum amounts of information in a document not retrievable through its title are discussed.  An analysis of the information transferred by different types of keywords is helpful in planning search strategies, e.g., 30% of chemical substances mentioned in journal articles are not discernable in their titles even when broad class names are used as synonyms.  Patents have considerably less informative titles than journal articles.  In nuclear science, report titles are also less informative than those of journal articles, but the proportion of reports with completely uninformative titles is now only 10% of the 1957 value.  Titles in chemistry are more informative than those in most other fields, but the use of alerting and other services based on titles requires a good understanding of the underlying information transfer principles. \n",
            "0.3395222625      428   The Information Content of Titles in Engineering Literature Bottle, Robert T. Since many alerting and information services rely very heavily on the use of titles to transfer information to the potential user, it is essential that he be aware of the proportion of the information contained in the complete document which will not be deducible from the title and which he will therefore miss.. Methods will be discussed for analyzing the relative information content of the titles of engineering paper and results presented for the amount and type of information lost through scanning title listing only.. Between one-third and one-half of indexable terms are not retrievable from article titles even if all possible synonyms and  related terms are used.. If all synonyms are used instead of one keyword the amount of information retrieved is increased by about 70 percent.. The problems of dealing with synonyms and with syntactical variants in searching titles indexes are discussed.. The possibility of using keywords in journal titles as supplementary retrieval tags is suggested since they were deemed useful in nearly one-third of the sample of papers analyzed.. \n",
            "0.2884997307      588   Are Titles of Chemical Papers Becoming More Informative? Tocatlian, Jacques J. The efficiency of key-work-in-context (KWIC) permuted-title indexes and their numerous variations is highly dependent upon authors' choices of titles for their papers.. Titles are important not only in commercial services, such as Chemical Titles, BASIC, Current Contents, and CA Condensates, but also in scanning primary journals, and in traditional library services, such as bibliographies.. It is generally believed and often stated that titles of chemical papers are becoming more informative as authors become increasingly aware of the importance of titles as \"carriers\" of information.. The present study was undertaken to test whether (1) titles of chemical papers are becoming more informative and (2) whether uninformative titles of chemical papers are being eliminated since the advent of the KWIC index in 1958.. The first hypothesis was tested by comparing titles published in 1948, 1958, and 1968 by the following criteria: (1) a count of substantive words in the title; (2) a count of all word matches between title and 10 leading substantive words selected from the abstract, with and without the use of a thesaurus; and (3) a count of word matches between title and 10 leading substantive words selected from the abstract, with and without the use of a thesaurus.. The second hypothesis was tested by comparing a count of short titles (with 3 or less substantive words) published in 1948, 1958, and 1968.. Results confirm that uninformative titles of chemical papers are being eliminated and that informative titles are becoming more informative since the advent of the KWIC index.. \n",
            "0.2641342469      602   The Efficiency of MEDLARS Titles for Retrieval Miller, William L. Previous research has indicated that the titles rather than index terms would, in the standard MEDLARS system, gave lower Recall but higher Precision.. A title searching technique is described which allows the number of references retrieved to be fixed before a search commences.. With this technique the greater applicability of title-terms offsets their relative paucity.. The title-searching technique is tested using queries put to MEDLARS.. These queries were not specially solicited for the test.. Title searching is compared with the standard MEDLARS index term search and with an index term search with fixed output size.. For equal output sizes, Title searching retrieves 4 relevant references for every 5 retrieved by index term searching.. Thus the relative retrieval efficiency of Title and Index terms is so close that the choice of one method or the other must be primarily on economic grounds.. \n",
            "0.2525271318      1280   Relative Effectiveness of Document Titles and Abstracts for Determining Relevance of Documents Resnick, A. Abstract.  Individuals who received documents through a selective dissemination of information system were asked to determine the relevance of documents to their work interests on the basis of titles and of abstracts.  The results indicate that there was no significant difference between the usefulness of titles and of abstracts for this purpose. \n",
            "0.2126794276      812   Comparative Efficiency of Searching Titles, Abstracts, and Terms in a Free-Text Data Base Barcer, F. H. Veal, D. C. Wyatt, B. K. The choice of the suitable data base for providing an information service is governed by factors of coverage, performance, and cost.. The cost of the data base to subscribers is a known quantity, and the coverage is decided by the data base producers.. This paper describes an investigation into the relative performance of the four major Chemical Abstracts Service magnetic tape data-base, Chemical Titles (CT), which contains the titles of citations only, Chemical Abstracts Condensates (CAC), which contains titles enriched with keyword phrases, Chemical-Biological Activities (CBAC),and Polymer Science and Technology (POST), both of which contain full digests in addition to titles.. The performance was measured in terms of the relative currency of the four data-bases, on the retrieval efficiency of profiles searched against them.. Fifty questions from industrial and government research organizations were used in the experiment.. Search profiles corresponding to these questions were constructed for searching against each database, output was assessed for relevance by users, and profile performance figures (precision and recall ratios) were calculated for each profile.. The overall retrieval efficiency of profiles searched against data-bases containing titles only, titles-plus-keywords, and titles-plus-digests, was calculated, and these results are presented.. \n",
            "0.2074240359      1298   Current Physics Information Koch, H. William A new concept in science communication will be given its first test in calendar year 1972.. Primary and secondary contents of a selected subset of the world's journal literature in physics will be provided in a variety of output formats.. Among them are a monthly microfilm containing the full texts of all articles in the set of journals (Current Physics Microform); an advance abstracts journal describing the articles (Current Physics Advance Abstracts); a printed, classified index of the titles of the articles (Current Physics Titles); and a computer tape index to the articles (Searchable Physics Information Notices).. \n",
            "0.2056551548      710   Development and Production of Chemical Titles, a Current Awareness Index Publication Prepared with the Aid of a Computer Freeman, R.R. Dysn, G.M. The introduction of Chemical titles in 1961 marked the first publication produced almost entirely by computers and other data-processing equipment.  The success of this innovation has generated many requests for more information about it.  With this in mind, we hope to encourage other organizations to make use of this technique for dissemination of information by presenting here a history of Chemical titles' development coupled with a description of its production. \n",
            "0.1897121805      835   Entry/Title Compression Code Access to Machine Readable Bibliographic Files Newman, William L. Buchinski, Edwin J. An entry/title compression code is proposed which will fulfill the following requirements at the Library, University of Saskatchewan: 1) entry/title access to MARC tapes; 2) entry/title access to the acquisitions and cataloguing in-process file; and 3) entry/title duplicate order edit within the acquisitions and cataloguing in-process file.. The study which produced the code and applications for the code are discussed.. \n",
            "0.1873408608      37   Machinelike Indexing by People Montgomery, C. Swanson, D.R. A study of several thousand entries in a classified bibliography of article titles (the Index Medicus) revealed that a large proportion of the title entries contained words identical to or synonymous with words of the corresponding subject heading.  It is inferred that a major part of the bibliography studied could have been compiled by a machine procedure operating on titles alone, provided the machine was supplied with a suitable synonym dictionary. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSBxbcT99ekH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}