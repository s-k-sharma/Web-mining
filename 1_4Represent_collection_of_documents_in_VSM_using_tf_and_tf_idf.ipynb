{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_4Represent collection of documents in VSM using tf and tf*idf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO1gXZR10e1ODPLYEEHyjLf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skssushil/Web-mining/blob/master/1_4Represent_collection_of_documents_in_VSM_using_tf_and_tf_idf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cTyXW7YntUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b89f0f04-24d7-4edf-88de-bde11c326278"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsHZmMrn5gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "with open('CISI.ALL') as f:\n",
        "    lines = \"\"\n",
        "    for l in f.readlines():\n",
        "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "    lines = lines.lstrip(\"\\n\").split(\"\\n\")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-dlf5Nzn8fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_set = {}\n",
        "doc_id = \"\"\n",
        "doc_text = \"\"\n",
        "for l in lines:\n",
        "    if l.startswith(\".I\"):\n",
        "        doc_id = l.split(\" \")[1].strip()\n",
        "    elif l.startswith(\".X\"):\n",
        "        doc_set[doc_id] = doc_text.lstrip(\" \")\n",
        "        doc_id = \"\"\n",
        "        doc_text = \"\"\n",
        "    else:\n",
        "        doc_text += l.strip()[3:] + \" \" # The first 3 characters of a line can be ignored."
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQWJoeKosKsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = []\n",
        "for i in doc_set.values():\n",
        "  dataset.append(i)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhoCrMqxsPq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb57f5b0-a587-49c7-cc61-7d99ed96ed09"
      },
      "source": [
        "N=len(dataset)\n",
        "print(N)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX68WlS48-1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "with open('CISI.QRY') as g:\n",
        "  qlines = \"\"\n",
        "  for m in g.readlines():\n",
        "    qlines += \"\\n\" + m.strip() if m.startswith(\".\") else \" \" + m.strip()\n",
        "  qlines = qlines.lstrip(\"\\n\").split(\"\\n\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vEevXj69C1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qry_set = {}\n",
        "qry_id = \"\"\n",
        "qry_text=\"\"\n",
        "for m in qlines:\n",
        "  if m.startswith(\".I\"):\n",
        "    qry_id = m.split(\" \")[1].strip()\n",
        "  elif m.startswith(\".W\"):\n",
        "    qry_set[qry_id] = m.strip()[3:]\n",
        "    qry_id = \"\"\n",
        "squery=qry_set[\"1\"]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL7xSCXIslYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_lower_case(data):\n",
        "  return np.char.lower(data)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD-gvAEqu8ZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_words(data):\n",
        "  stop_words = stopwords.words('english')\n",
        "  words = word_tokenize(str(data))\n",
        "  new_text = \"\"\n",
        "  for w in words:\n",
        "    if w not in stop_words and len(w) > 1:\n",
        "      new_text = new_text + \" \" + w\n",
        "  return new_text"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMAHI1bru-Im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(data):\n",
        "  symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
        "  for i in range(len(symbols)):\n",
        "    data = np.char.replace(data, symbols[i], ' ')\n",
        "    data = np.char.replace(data, \"  \", \" \")\n",
        "    data = np.char.replace(data, ',', '')\n",
        "  return data"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67kO5X1tvAbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_apostrophe(data):\n",
        "  return np.char.replace(data, \"'\", \"\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAWZhjkdvCuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming(data):\n",
        "  stemmer= PorterStemmer()  \n",
        "  tokens = word_tokenize(str(data))\n",
        "  new_text = \"\"\n",
        "  for w in tokens:\n",
        "    new_text = new_text + \" \" + stemmer.stem(w)\n",
        "  return new_text"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ByQPnQ4vFgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import inflect \n",
        "p = inflect.engine()   \n",
        "# convert number into words \n",
        "def convert_number(text): \n",
        "  temp_str = text.split() \n",
        "  new_string = []  \n",
        "  for word in temp_str:\n",
        "    if word.isdigit(): \n",
        "      temp = p.number_to_words(word) \n",
        "      new_string.append(temp) \n",
        "    else:\n",
        "      new_string.append(word) \n",
        "      temp_str = ' '.join(new_string) \n",
        "  return temp_str"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKqY9tfWvHnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(data):\n",
        "  data = convert_number(data)\n",
        "  data = convert_lower_case(data)\n",
        "  data = remove_punctuation(data) #remove comma seperately\n",
        "  data = remove_apostrophe(data)\n",
        "  data = remove_stop_words(data)\n",
        "  data = stemming(data)\n",
        "  data = remove_punctuation(data)\n",
        "  data = stemming(data) #needed again as we need to stem the words\n",
        "  data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
        "  data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
        "  data = convert_number(data)\n",
        "  return data"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPlDNQPTvJsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_text = []\n",
        "for i in dataset[:N]:\n",
        "  processed_text.append(word_tokenize(str(preprocess(i))))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkehvI7BvfWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DF = {}\n",
        "for i in range(N):\n",
        "  tokens = processed_text[i]\n",
        "  for w in tokens:\n",
        "    try:\n",
        "      DF[w].add(i)\n",
        "    except:\n",
        "      DF[w] = {i}\n",
        "for i in DF:\n",
        "  DF[i] = len(DF[i])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLOPZwHUv7J_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db3be557-feb9-4a17-ede5-a7fb24864afe"
      },
      "source": [
        "total_vocab_size = len(DF)\n",
        "print(total_vocab_size)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6830\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTrKiU7hwGPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_vocab = [x for x in DF]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q83798vXwP65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "663b4a31-5626-4217-cf81-9617ca78bb00"
      },
      "source": [
        "print(total_vocab[:20])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['eighteen', 'edit', 'dewey', 'decim', 'classif', 'comaromi', 'present', 'studi', 'histori', 'first', 'ddc', 'publish', 'one', 'thousand', ',', 'eight', 'hundred', 'and', 'seventy-six', 'eighteenth']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf99rQcvx9F9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doc_freq(word):\n",
        "  c = 0\n",
        "  try:\n",
        "    c = DF[word]\n",
        "  except:\n",
        "    pass\n",
        "  return c"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGQd-vfiwUDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = 0\n",
        "tf_idf = {}\n",
        "for i in range(N):    \n",
        "    tokens = processed_text[i]    \n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)    \n",
        "    for token in np.unique(tokens):        \n",
        "        tf = counter[token]/words_count\n",
        "        df = doc_freq(token)\n",
        "        idf = np.log((N+1)/(df+1))        \n",
        "        tf_idf[doc, token] = tf*idf\n",
        "    doc += 1"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWFutrsWxqJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = 0\n",
        "tf_idf = {}\n",
        "for i in range(N):    \n",
        "    tokens = processed_text[i]    \n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)    \n",
        "    for token in np.unique(tokens):        \n",
        "        tf = counter[token]/words_count\n",
        "        df = doc_freq(token)\n",
        "        idf = np.log((N+1)/(df+1))        \n",
        "        tf_idf[doc, token] = tf*idf\n",
        "    doc += 1"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlzL-k-zlvrA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c6f370bc-acc9-483d-fd12-de49d81ca886"
      },
      "source": [
        "print(tf_idf)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5CANIK2ytN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa19a18c-0628-4671-ea61-8d4f7c2366d6"
      },
      "source": [
        "len(tf_idf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc1UzyOFzhNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matching_score(k, query):\n",
        "  preprocessed_query = preprocess(query)\n",
        "  tokens = word_tokenize(str(preprocessed_query))\n",
        "  print(\"\\nQuery:\", query)  \n",
        "  query_weights = {}\n",
        "  for key in tf_idf:\n",
        "    if key[1] in tokens:\n",
        "      try:\n",
        "        query_weights[key[0]] += tf_idf[key]\n",
        "      except:\n",
        "        query_weights[key[0]] = tf_idf[key]    \n",
        "  query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)\n",
        "  print(\"\")  \n",
        "  print(\"Top Matching Documents\")  \n",
        "  l = []\n",
        "  for i in query_weights[:10]:\n",
        "    l.append(i[0])    \n",
        "  print(l)\n",
        "  for i in range(k):\n",
        "    x=l[i]\n",
        "    print(\"    \", l[i],\" \", dataset[x][:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dw6TJ40z8Lv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "28427e3c-8e1e-4267-8509-2e241f11fd72"
      },
      "source": [
        "matching_score(10, squery)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Query: What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n",
            "\n",
            "Top Matching Documents\n",
            "[1293, 448, 446, 314, 1280, 443, 428, 564, 721, 1162]\n",
            "     1293   Automatic Text Analysis Salton, G. In this article the principal experiments in automatic text analy\n",
            "     448   Situational Relevance Wilson, Patrick The concept of situational relevance is introduced, based on W\n",
            "     446   A Note on the Concept of \"Relevance\" Foskett, D.J. Two recent articles in this journal (Konigova [1]\n",
            "     314   Automatic Abstracting and Indexing - Survey and Recommendations Edmundson, H.P. Wyllys, R.E. In prep\n",
            "     1280   Relative Effectiveness of Document Titles and Abstracts for Determining Relevance of Documents Resni\n",
            "     443   On Relevance as a Measure Coffman, William Relevance is defined as a measure of information conveyed\n",
            "     428   The Information Content of Titles in Engineering Literature Bottle, Robert T. Since many alerting an\n",
            "     564   Computer Evaluation of Indexing and Text Processing Salton, G. Lesk, M. E. Automatic indexing method\n",
            "     721   Information Transfer Limitations of Titles of Chemical Documents Bottle, R.R. Seeley, C.R. Some meth\n",
            "     1162   The Thesaurus and some Methods of its Construction.  Part 1. Ovchinnikov, V.G. It is suggested that \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOvDr01d0Klu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_sim(a, b):\n",
        "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "    return cos_sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1KyJtwM0fyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = np.zeros((N, total_vocab_size))\n",
        "for i in tf_idf:\n",
        "    try:\n",
        "        ind = total_vocab.index(i[1])\n",
        "        D[i[0]][ind] = tf_idf[i]\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSIhv9ox0lLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_vector(tokens):\n",
        "    Q = np.zeros((len(total_vocab)))\n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)\n",
        "    query_weights = {}\n",
        "    for token in np.unique(tokens):   \n",
        "        tf = counter[token]/words_count\n",
        "        df = doc_freq(token)\n",
        "        idf = math.log((N+1)/(df+1))\n",
        "        try:\n",
        "            ind = total_vocab.index(token)\n",
        "            Q[ind] = tf*idf\n",
        "        except:\n",
        "            pass\n",
        "    return Q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnwswVva0n1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(k, query):\n",
        "    print(\"Cosine Similarity\")\n",
        "    preprocessed_query = preprocess(query)\n",
        "    tokens = word_tokenize(str(preprocessed_query))\n",
        "    print(\"\\nQuery:\", query)\n",
        "    print(\"\")\n",
        "    #print(tokens)\n",
        "    d_cosines = []\n",
        "    query_vector = gen_vector(tokens)\n",
        "    for d in D:\n",
        "        d_cosines.append(cosine_sim(query_vector, d))\n",
        "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
        "    print(\"\")  \n",
        "    print(out)\n",
        "    print(\"Cosine similarity\",\" id \", \" Document\")\n",
        "    for i in range(k):\n",
        "      x=out[i]\n",
        "      print(round(d_cosines[x],10),\"    \", out[i],\" \", dataset[x][:100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3yLjitS0r9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "33c30c97-c41e-46e5-aa8b-660298d28c43"
      },
      "source": [
        "cosine_similarity(10,squery)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine Similarity\n",
            "\n",
            "Query: What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n",
            "\n",
            "\n",
            "[ 721  428  588  602 1280  812 1298  710  835   37]\n",
            "Cosine similarity  id   Document\n",
            "0.3699350395      721   Information Transfer Limitations of Titles of Chemical Documents Bottle, R.R. Seeley, C.R. Some meth\n",
            "0.3395118108      428   The Information Content of Titles in Engineering Literature Bottle, Robert T. Since many alerting an\n",
            "0.2880003582      588   Are Titles of Chemical Papers Becoming More Informative? Tocatlian, Jacques J. The efficiency of key\n",
            "0.2641313807      602   The Efficiency of MEDLARS Titles for Retrieval Miller, William L. Previous research has indicated th\n",
            "0.2525271318      1280   Relative Effectiveness of Document Titles and Abstracts for Determining Relevance of Documents Resni\n",
            "0.2126737211      812   Comparative Efficiency of Searching Titles, Abstracts, and Terms in a Free-Text Data Base Barcer, F.\n",
            "0.2073121274      1298   Current Physics Information Koch, H. William A new concept in science communication will be given it\n",
            "0.2056349244      710   Development and Production of Chemical Titles, a Current Awareness Index Publication Prepared with t\n",
            "0.1897121805      835   Entry/Title Compression Code Access to Machine Readable Bibliographic Files Newman, William L. Buchi\n",
            "0.1873364171      37   Machinelike Indexing by People Montgomery, C. Swanson, D.R. A study of several thousand entries in a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSBxbcT99ekH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}