{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Term Document matrix and Cosine similarity",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8PQZuPFwk8ep6+zhWbMIx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skssushil/Web-mining/blob/master/Term_Document_matrix_and_Cosine_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7HL8kIO2NMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cd4c8591-8624-4978-e28d-40972781763c"
      },
      "source": [
        "import urllib.request\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import math\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKDTmyDOxyDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b9430217-733b-45da-c0bc-28af65f5d98b"
      },
      "source": [
        "from google.colab import files\n",
        "try:\n",
        "    from googlesearch import search\n",
        "except ImportError:\n",
        "    print(\"No module named 'google' found\")\n",
        "# to search\n",
        "query =[\"tutorial on datastructure\", \"data science\", \"web mining\",\" Artificial intelegence\"]\n",
        "url=[]\n",
        "for i in query:\n",
        "  q=[]\n",
        "  for j in search(i, tld=\"com\", num=5, stop=10, pause=2):\n",
        "    q.append(j)\n",
        "  url.append(q)\n",
        "print(url)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['https://www.tutorialspoint.com/data_structures_algorithms/index.htm', 'https://www.tutorialspoint.com/data_structures_algorithms/data_structures_basics.htm', 'https://www.tutorialspoint.com/data_structures_algorithms/algorithms_basics.htm', 'https://www.tutorialspoint.com/data_structures_algorithms/graph_data_structure.htm', 'https://www.tutorialspoint.com/data_structures_algorithms/data_structure_overview.htm', 'https://www.javatpoint.com/data-structure-tutorial', 'https://www.javatpoint.com/data-structure-interview-questions', 'https://www.javatpoint.com/data-structure-introduction', 'https://www.javatpoint.com/singly-linked-list', 'https://www.javatpoint.com/data-structure-array'], ['https://www.kainos.com/my-experience-as-a-data-scientist', 'https://en.wikipedia.org/wiki/Data_science', 'https://en.wikipedia.org/wiki/Master_in_Data_Science', 'https://en.wikipedia.org/wiki/Big_data', 'https://en.wikipedia.org/wiki/Data_analysis', 'https://en.wikipedia.org/wiki/Unstructured_data', 'https://datascience.berkeley.edu/about/what-is-data-science/', 'https://www.innoarchitech.com/blog/what-is-data-science-does-data-scientist-do', 'https://dataconomy.com/2020/07/9-best-practices-every-data-science-leader-should-follow/', 'https://thedcpost.com/data-science-free-webinar/'], ['https://www.researchgate.net/figure/Web-Mining-Categories-5_fig1_276928728', 'https://en.wikipedia.org/wiki/Web_mining', 'https://en.wikipedia.org/wiki/Web_mining#Web_mining_types', 'https://en.wikipedia.org/wiki/Web_mining#Web_usage_mining', 'https://en.wikipedia.org/wiki/Web_mining#Web_structure_mining', 'https://en.wikipedia.org/wiki/Web_mining#Web_content_mining', 'https://www.geeksforgeeks.org/web-mining/', 'https://www.techopedia.com/definition/15634/web-mining', 'https://searchcustomerexperience.techtarget.com/definition/Web-mining', 'https://www.sciencedirect.com/topics/computer-science/web-mining'], ['https://en.wikipedia.org/wiki/Artificial_intelligence', 'https://en.wikipedia.org/wiki/History_of_artificial_intelligence', 'https://en.wikipedia.org/wiki/Outline_of_artificial_intelligence', 'https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach', 'https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/powerful-ai-can-now-be-trained-on-a-single-computer', 'http://news.mit.edu/2020/faculty-receive-funding-develop-novel-ai-techniques-combat-covid-19-0717/', 'https://www.forbes.com/sites/cathyhackl/2020/07/18/how-4-companies-are-using-ai-to-solve-waste-issues-on-earth--in-space/', 'https://builtin.com/artificial-intelligence', 'https://futureoflife.org/background/benefits-risks-of-artificial-intelligence/', 'https://www.investopedia.com/terms/a/artificial-intelligence-ai.asp']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKtqhkF79lxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_text=\" \""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2pPSYYXLxIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Length=len(url)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_4NZpgGMVIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Length1=len(url[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7CVpvP3x7k3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=[]\n",
        "for i in range(Length):\n",
        "  for j in range(Length1):\n",
        "    req = urllib.request.Request(url[i][j], headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    data = urllib.request.urlopen(req).read()\n",
        "    html= data.decode()\n",
        "    soup = BeautifulSoup(html,features=\"lxml\")\n",
        "    for script in soup([\"script\", \"style\"]):\n",
        "      script.extract()\n",
        "    # get text\n",
        "    text = soup.get_text()\n",
        "    # break into lines and remove leading and trailing space on each\n",
        "    lines = (line.strip() for line in text.splitlines())\n",
        "    # break multi-headlines into a line each\n",
        "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "    # drop blank lines\n",
        "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "  f_text=f_text+text\n",
        "  dataset.append(f_text)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FxI6zhPPdpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M=len(dataset)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrytoZxcnuRt",
        "colab_type": "text"
      },
      "source": [
        "Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_H0RJjynI5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_lower_case(data):\n",
        "  return np.char.lower(data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCIPhwW-Aa3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_string_special_characters(data):\n",
        "    # removes special characters with ' '\n",
        "    stripped = re.sub('[^a-zA-z\\s]', '', data)\n",
        "    stripped = re.sub('_', '', stripped)\n",
        "\n",
        "    # Change any white space to one space\n",
        "    stripped = re.sub('\\s+', ' ', stripped)\n",
        "\n",
        "    # Remove start and end white spaces\n",
        "    stripped = stripped.strip()\n",
        "    return stripped.lower()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSaA9wl_AitZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming(data):\n",
        "    stemmer= PorterStemmer()    \n",
        "    tokens = word_tokenize(str(data))\n",
        "    new_text = \"\"\n",
        "    for w in tokens:\n",
        "        new_text = new_text + \" \" + stemmer.stem(w)\n",
        "    return new_text"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YVdzhfqApv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_numbers(data):\n",
        "    tokens = word_tokenize(str(data))\n",
        "    new_text = \"\"\n",
        "    for w in tokens:\n",
        "        try:\n",
        "            w = num2words(int(w))\n",
        "        except:\n",
        "            a = 0\n",
        "        new_text = new_text + \" \" + w\n",
        "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
        "    return new_text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU-LGOgUAsTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stopword removal\n",
        "def remove_stop_words(data):\n",
        "    stop_words = stopwords.words('english')\n",
        "    words = word_tokenize(str(data))\n",
        "    new_text = \"\"\n",
        "    for w in words:\n",
        "        if w not in stop_words and len(w) > 1:\n",
        "            new_text = new_text + \" \" + w\n",
        "    return new_text"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTkJEAlSoIGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(data):\n",
        "  Clean_data= remove_string_special_characters(data)  # removing special character\n",
        "  Clean_data=stemming(Clean_data)\n",
        "  Clean_data= convert_numbers(Clean_data)\n",
        "  Clean_data=remove_stop_words(Clean_data)\n",
        "  return Clean_data\n",
        "# preprocessing of data completed"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX3LPZk4ogV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_text1 = []\n",
        "for i in dataset[:M]:\n",
        "    processed_text1.append(str(preprocess(i)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIheX2VDQ5Uw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53c124f5-c90e-4aa1-fd39-cbb3c0a2b452"
      },
      "source": [
        "print(len(processed_text1))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72k996WwPKYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'Doc1': [processed_text1[0]],'Doc2': [processed_text1[1]],'Doc3': [processed_text1[2]],'Doc4': [processed_text1[3]]})"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_hgh2YBP7JC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c50dabab-fcbc-4af3-a08e-3b59b1b09025"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Doc1  ...                                               Doc4\n",
            "0   ds array javatpoint home data structur java s...  ...   ds array javatpoint home data structur java s...\n",
            "\n",
            "[1 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB40aRv0P-I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize\n",
        "vectorizer = TfidfVectorizer()\n",
        "doc_vec = vectorizer.fit_transform(df.iloc[0])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4elQKdfRp-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dataFrame\n",
        "df2 = pd.DataFrame(doc_vec.toarray().transpose(),\n",
        "                   index=vectorizer.get_feature_names())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roX076cdRu4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change column headers\n",
        "df2.columns = df.columns"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InawEcFLS98R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3=pd.DataFrame(vectorizer.get_feature_names())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdCcGjpcRz8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "cdafbf82-4137-4072-91df-b3bc5091e12f"
      },
      "source": [
        "print(df2.head(50))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   Doc1      Doc2      Doc3      Doc4\n",
            "aapl           0.000000  0.000000  0.000000  0.005142\n",
            "abandon        0.000000  0.000000  0.004487  0.004054\n",
            "abil           0.000000  0.000000  0.008975  0.012162\n",
            "abl            0.000000  0.000000  0.000000  0.005142\n",
            "aboul          0.000000  0.000000  0.004487  0.004054\n",
            "abov           0.010431  0.007742  0.011881  0.013417\n",
            "absolut        0.000000  0.000000  0.008975  0.008108\n",
            "abstract       0.000000  0.000000  0.004487  0.004054\n",
            "abstractrec    0.000000  0.000000  0.004487  0.004054\n",
            "academi        0.000000  0.018939  0.007266  0.009846\n",
            "acceler        0.000000  0.009470  0.003633  0.003282\n",
            "accept         0.010431  0.007742  0.005940  0.005367\n",
            "access         0.062588  0.046452  0.035642  0.032201\n",
            "accessshop     0.000000  0.000000  0.004487  0.004054\n",
            "accident       0.000000  0.000000  0.004487  0.004054\n",
            "accomplish     0.000000  0.000000  0.004487  0.004054\n",
            "accord         0.000000  0.000000  0.008975  0.008108\n",
            "account        0.000000  0.000000  0.004487  0.020271\n",
            "accuraci       0.000000  0.000000  0.008975  0.008108\n",
            "achiev         0.000000  0.000000  0.008975  0.012162\n",
            "across         0.000000  0.000000  0.017949  0.020271\n",
            "act            0.000000  0.000000  0.000000  0.005142\n",
            "action         0.000000  0.000000  0.004487  0.020271\n",
            "activ          0.000000  0.000000  0.112184  0.105407\n",
            "activityview   0.000000  0.000000  0.004487  0.004054\n",
            "actorsget      0.000000  0.000000  0.004487  0.004054\n",
            "actual         0.000000  0.000000  0.004487  0.004054\n",
            "ad             0.000000  0.000000  0.026924  0.024325\n",
            "adapt          0.000000  0.000000  0.004487  0.004054\n",
            "add            0.000000  0.000000  0.013462  0.012162\n",
            "addit          0.000000  0.028409  0.032696  0.029539\n",
            "address        0.156471  0.116130  0.056433  0.050984\n",
            "adept          0.000000  0.000000  0.008975  0.008108\n",
            "adequ          0.000000  0.000000  0.004487  0.004054\n",
            "adjust         0.000000  0.000000  0.004487  0.004054\n",
            "admittedli     0.000000  0.000000  0.004487  0.004054\n",
            "advanc         0.010431  0.007742  0.011881  0.013417\n",
            "advantag       0.010431  0.007742  0.017821  0.016100\n",
            "adversari      0.000000  0.000000  0.013462  0.012162\n",
            "advertis       0.000000  0.018939  0.025430  0.029539\n",
            "advertisingto  0.000000  0.000000  0.004487  0.004054\n",
            "advic          0.000000  0.000000  0.008975  0.012162\n",
            "advisor        0.000000  0.000000  0.000000  0.010284\n",
            "advisori       0.000000  0.000000  0.000000  0.005142\n",
            "adword         0.010431  0.007742  0.002970  0.002683\n",
            "affect         0.000000  0.000000  0.022437  0.024325\n",
            "affili         0.010431  0.007742  0.002970  0.002683\n",
            "age            0.000000  0.000000  0.004487  0.004054\n",
            "agenc          0.000000  0.000000  0.017949  0.016217\n",
            "aggreg         0.000000  0.000000  0.008975  0.008108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ-SRfVqmwru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_list=[*url[0],*url[1],*url[2],*url[3]]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCWnTL3sm_L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc=[]\n",
        "for k in url_list:\n",
        "  req = urllib.request.Request(k, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "  data = urllib.request.urlopen(req).read()\n",
        "  html= data.decode()\n",
        "  soup = BeautifulSoup(html,features=\"lxml\")\n",
        "  for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "  # get text\n",
        "  text = soup.get_text()\n",
        "  # break into lines and remove leading and trailing space on each\n",
        "  lines = (line.strip() for line in text.splitlines())\n",
        "  # break multi-headlines into a line each\n",
        "  chunks = (phrase.strip() for line in lines for phrase in line.split(\" \"))\n",
        "  # drop blank lines\n",
        "  text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "  doc.append(text)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7MtTl3XnB-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N=len(doc)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOoqRks3ngfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_text = []\n",
        "for i in doc[:N]:\n",
        "    processed_text.append(word_tokenize(str(preprocess(i))))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mblB50kEnjsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17855aab-51e3-469c-bca1-9dc5e1c97997"
      },
      "source": [
        "len(processed_text)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB0wwMxXoDZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DF = {}\n",
        "for i in range(N):\n",
        "    tokens = processed_text[i]\n",
        "    for w in tokens:\n",
        "        try:\n",
        "            DF[w].add(i)\n",
        "        except:\n",
        "            DF[w] = {i}\n",
        "for i in DF:\n",
        "    DF[i] = len(DF[i])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA4HdN2zoF9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09b255df-fc92-4dfd-e30a-d74b9f69c687"
      },
      "source": [
        "total_vocab_size = len(DF)\n",
        "print(total_vocab_size)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWbE2uspoIMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_vocab = [x for x in DF]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdPHq50ZoLcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "853b4254-c887-4b23-b4f7-f615383934b0"
      },
      "source": [
        "print(total_vocab[:20])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data', 'structur', 'algorithm', 'tutori', 'tutorialspoint', 'home', 'job', 'tool', 'code', 'ground', 'current', 'affair', 'upsc', 'note', 'onlin', 'tutor', 'whiteboard', 'net', 'meet', 'tutorix']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDonY4zOoNYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doc_freq(word):\n",
        "    c = 0\n",
        "    try:\n",
        "        c = DF[word]\n",
        "    except:\n",
        "        pass\n",
        "    return c"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WAPGRnBoSPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = 0\n",
        "tf_idf = {}\n",
        "for i in range(N):    \n",
        "    tokens = processed_text[i]    \n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)    \n",
        "    for token in np.unique(tokens):        \n",
        "        tf = counter[token]/words_count\n",
        "        df = doc_freq(token)\n",
        "        idf = np.log((N+1)/(df+1))        \n",
        "        tf_idf[doc, token] = tf*idf\n",
        "    doc += 1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUzLz_ASoU7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "787e985d-b748-491e-c983-a4df553fe54f"
      },
      "source": [
        "len(tf_idf)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30870"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDE5_lAUoYM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_sim(a, b):\n",
        "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "    return cos_sim"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gTPGSz9oaQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = np.zeros((N, total_vocab_size))\n",
        "for i in tf_idf:\n",
        "    try:\n",
        "        ind = total_vocab.index(i[1])\n",
        "        D[i[0]][ind] = tf_idf[i]\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQRPhjFyocxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_vector(tokens):\n",
        "    Q = np.zeros((len(total_vocab)))\n",
        "    counter = Counter(tokens)\n",
        "    words_count = len(tokens)\n",
        "    query_weights = {}\n",
        "    for token in np.unique(tokens):   \n",
        "        tf = counter[token]/words_count\n",
        "        df = doc_freq(token)\n",
        "        idf = math.log((N+1)/(df+1))\n",
        "        try:\n",
        "            ind = total_vocab.index(token)\n",
        "            Q[ind] = tf*idf\n",
        "        except:\n",
        "            pass\n",
        "    return Q"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7on4uy8ofYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(query):\n",
        "    preprocessed_query = preprocess(query)\n",
        "    tokens = word_tokenize(str(preprocessed_query))\n",
        "    print(\"\")\n",
        "    #print(tokens)\n",
        "    d_cosines = []\n",
        "    query_vector = gen_vector(tokens)\n",
        "    for d in D:\n",
        "        d_cosines.append(cosine_sim(query_vector, d))\n",
        "    return d_cosines"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4olrD_NoiG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ad265a0b-04b2-4d85-9770-7479de9c03d5"
      },
      "source": [
        "Arr1=np.array(cosine_similarity(query[0]))\n",
        "Arr2=np.array(cosine_similarity(query[1]))\n",
        "Arr3=np.array(cosine_similarity(query[2]))\n",
        "Arr4=np.array(cosine_similarity(query[3]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqlg0Hgcok8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Arr1=np.sort(Arr1)[::-1]\n",
        "Arr2=np.sort(Arr2)[::-1]\n",
        "Arr3=np.sort(Arr3)[::-1]\n",
        "Arr4=np.sort(Arr4)[::-1]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bKV6siaonq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3b0e5765-af82-4ce5-ef3c-e73a52f7d15e"
      },
      "source": [
        "print(Arr1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.05914158 0.03724629 0.03537235 0.03494568 0.03190127 0.02899576\n",
            " 0.02232992 0.01793591 0.01260646 0.01095667 0.00977259 0.00761484\n",
            " 0.0050974  0.00034792 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej1Rdlhlopl5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e1eb4b43-952b-472f-a5ec-a8232649b79b"
      },
      "source": [
        "print(Arr2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.17361538 0.11749816 0.10196374 0.09628295 0.09400704 0.07020909\n",
            " 0.05904454 0.05748283 0.04685354 0.04548307 0.04521942 0.04521942\n",
            " 0.04521942 0.04521942 0.04521942 0.04438323 0.04297346 0.03443382\n",
            " 0.03247782 0.03042162 0.03019721 0.0279758  0.02097895 0.02014976\n",
            " 0.01607328 0.01554388 0.01500259 0.01201115 0.0108066  0.01009432\n",
            " 0.00919175 0.00806413 0.0058309  0.00547935 0.00535529 0.00461734\n",
            " 0.00229788 0.00214646 0.00059342 0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA53GhoWos-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1f036acd-04cd-4cfc-d3ae-99cee3f8f455"
      },
      "source": [
        "print(Arr3)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.55935501 0.55935501 0.55935501 0.55935501 0.55935501 0.36243975\n",
            " 0.31176193 0.19518365 0.17731083 0.14234353 0.03680619 0.02819297\n",
            " 0.01376431 0.01339877 0.01058761 0.01025469 0.00916198 0.00868684\n",
            " 0.00644752 0.00615694 0.00498216 0.00464664 0.00356542 0.00321147\n",
            " 0.00320244 0.00315377 0.00259173 0.00207528 0.00159614 0.00155535\n",
            " 0.00151263 0.00143951 0.00119572 0.00094755 0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya9lm9NwowRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5636630c-73a1-4cbe-95b6-30246fe725b3"
      },
      "source": [
        "print(Arr4)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.30515465 0.30195095 0.23974559 0.15934495 0.15915839 0.13675317\n",
            " 0.06437574 0.04725936 0.04517847 0.04101147 0.02878921 0.02633624\n",
            " 0.02361456 0.02361456 0.02361456 0.02361456 0.02361456 0.00835428\n",
            " 0.00714306 0.00574055 0.00530965 0.00256087 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmO6x7CqoyM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    }
  ]
}